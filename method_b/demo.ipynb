{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch\n",
    "# ! pip install torchtext==0.6.0\n",
    "# ! pip install scapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import errno\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from classifier import NLIModel\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define how to preprocess the text data\n",
    "TEXT = data.Field(lower=True, sequential=True, tokenize=lambda text: [token.text for token in spacy_en.tokenizer(text)])\n",
    "# Define how to process the labels\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, unk_token=None)\n",
    "\n",
    "fields = [('premise', TEXT), ('hypothesis', TEXT), ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = data.TabularDataset.splits(\n",
    "        path='./',  # Directory of your CSV files\n",
    "        train='train.csv', validation='dev.csv',\n",
    "        format='csv',\n",
    "        fields=fields,\n",
    "        skip_header=True  # If your CSV has a header\n",
    ")\n",
    "\n",
    "# Build the vocabulary only for the TEXT field from the training set\n",
    "TEXT.build_vocab(train_data, vectors=\"glove.840B.300d\")\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': ['boy', 'wearing', 'red', 'hat', ',', 'blue', 'jacket', 'pushing', 'plow', 'in', 'snow', '.'], 'hypothesis': ['the', 'boy', 'is', 'surrounded', 'by', 'snow']}\n",
      "{'premise': ['a', 'blond', 'woman', 'in', 'a', 'black', 'shirt', 'is', 'standing', 'behind', 'a', 'counter', '.'], 'hypothesis': ['the', 'woman', 'is', 'standing', '.']}\n",
      "{'premise': ['three', 'people', 'in', 'uniform', 'are', 'outdoors', 'and', 'are', 'observing', 'a', 'scene', 'which', 'is', 'out', 'of', 'the', 'picture', '.'], 'hypothesis': ['uniformed', 'people', 'are', 'outside']}\n"
     ]
    }
   ],
   "source": [
    "fields = [('premise', TEXT), ('hypothesis', TEXT)]\n",
    "\n",
    "test_data = data.TabularDataset(\n",
    "        path='./test.csv',  # Directory of your CSV files\n",
    "        format='csv',\n",
    "        fields=fields,\n",
    "        skip_header=True  # If your CSV has a header\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "        print(vars(test_data.examples[i]))  # Print the first training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: boy a three a a a a a three man a a a family the a two a a a the a a two a an three woman a a a two there a a a an a a a a four a an two a a a a a female the a a a two a two a four a a a a a there a lot a a men a a a a female a a a a a two a a boy three two a men a a a a five a a a the a a in a men a people a motorcycle a the a two a an a along a two three rider young phone the a a a a a a\n",
      "Hypothesis: the the uniformed the a the a a people two a a there a the group no nobody there the there a a two a the some a a the fans people there a the a an the a a there four a an the a a a the a <unk> the a cyclists a the a two a some the the the the a children the people a a men a the a the the a a a a the two the a a three people a guys a a a a there the a a a a a the a the the people a camel a the the two someone the the along a two the horse the phone a the a a a a the\n"
     ]
    }
   ],
   "source": [
    "# Create the test iterator\n",
    "test_iter = data.Iterator(\n",
    "    dataset=test_data,\n",
    "    batch_size=128, # config.batch_size\n",
    "    device=device,\n",
    "    sort=False,  # No need to sort test data\n",
    "    sort_within_batch=False,\n",
    "    shuffle=False  # Do not shuffle test data\n",
    ")\n",
    "\n",
    "for batch in test_iter:\n",
    "    premise = batch.premise\n",
    "    hypothesis = batch.hypothesis\n",
    "\n",
    "    # Since batch_size=1, you directly access the first (and only) item in the batch\n",
    "    premise_sentence = ' '.join([TEXT.vocab.itos[idx] for idx in premise[0]])\n",
    "    hypothesis_sentence = ' '.join([TEXT.vocab.itos[idx] for idx in hypothesis[0]])\n",
    "    print(\"Premise:\", premise_sentence)\n",
    "    print(\"Hypothesis:\", hypothesis_sentence)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best dev model\n",
    "test_model = torch.load(\"best_HBMP_600D_devacc_72.17_epoch_3.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3302\n"
     ]
    }
   ],
   "source": [
    "test_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():  # Do not calculate gradients\n",
    "    for batch in test_iter:\n",
    "        \n",
    "        # Move batch data to the correct device\n",
    "        batch.premise, batch.hypothesis = batch.premise.to(device), batch.hypothesis.to(device)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = test_model(batch)\n",
    "        \n",
    "        # Convert predictions to labels\n",
    "        predicted_labels = predictions.argmax(1)\n",
    "        \n",
    "        test_predictions.extend(predicted_labels.cpu().numpy())\n",
    "  \n",
    "print(len(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to './Group_9_B.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the predictions to a CSV file\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the predictions list to a DataFrame\n",
    "predictions_df = pd.DataFrame(test_predictions, columns=['prediction'])\n",
    "\n",
    "# Save to a new CSV file\n",
    "predictions_df.to_csv('./Group_9_B.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to './Group_9_B.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
