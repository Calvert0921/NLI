{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3358d09-ac33-4494-b132-cfb5c30774aa",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ba397-7c4b-4385-b075-159a49658309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install torchtext==0.6.0\n",
    "# !pip install transformers sentence-transformers\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68e41df0-87b7-4bbe-8fed-deabbf4c017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "import torch\n",
    "import random\n",
    "from transformers import DebertaTokenizer, DebertaModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74a1e4-2b47-4f5f-9002-04abc6efa63e",
   "metadata": {},
   "source": [
    "# Load models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe72e4b1-abb7-42f0-818d-5cb8cd446da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('dev.csv')\n",
    "svm_glove = load('models/svm_glove.joblib')\n",
    "svm_DeBERTa = load('models/svm_DeBERTa.joblib')\n",
    "svm_sBERT = load('models/svm_sBERT.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8565e5f-69bb-410d-8277-65099dedc3ed",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c410669-6938-4143-8274-104e24696622",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b063d-bdce-4aa7-86a6-9972e888f637",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5f57e94-652d-4f97-bb6c-43fed13d1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "count = 0\n",
    "num_inv = 0\n",
    "num_oov = 0\n",
    "glove_mode = True\n",
    "\n",
    "update_inv_mode = False\n",
    "update_oov_mode = False\n",
    "word_mode = (glove_mode, update_inv_mode, update_oov_mode)\n",
    "\n",
    "# Load SpaCy English tokenizer\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "inputs = data.Field(lower=True, tokenize=lambda text: [token.text for token in spacy_en.tokenizer(text)])\n",
    "\n",
    "test_data['processed_premise'] = test_data['premise'].astype(str).apply(inputs.preprocess)\n",
    "test_data['processed_hypothesis'] = test_data['hypothesis'].astype(str).apply(inputs.preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fa137d-6e19-4288-935f-aef4c7360940",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9552211d-0aa8-498c-8050-ea14a689f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(tokens):\n",
    "    embeddings = torch.zeros(300)\n",
    "    for word in tokens:\n",
    "        if word in wv_dict:\n",
    "            embeddings += wv_arr[wv_dict[word]]\n",
    "        else:\n",
    "            embeddings += torch.Tensor([random.uniform(-0.05, 0.05) for i in range(EMBEDDING_DIM)])\n",
    "    embeddings = embeddings / len(tokens)\n",
    "    return embeddings\n",
    "\n",
    "# Load GloVe embeddings\n",
    "EMBEDDING_DIM = 300\n",
    "glove = GloVe(name='840B', dim=EMBEDDING_DIM) # Using GloVe with 840 billion tokens and 300 dimensions\n",
    "\n",
    "# GloVe's vocabulary and vectors\n",
    "wv_dict = glove.stoi  # Word to index mapping\n",
    "wv_arr = glove.vectors  # Embedding matrix\n",
    "wr_size = glove.dim  # Embedding dimension\n",
    "\n",
    "test_data['premise_vec'] = test_data['processed_premise'].apply(embedding)\n",
    "test_data['hypothesis_vec'] = test_data['processed_hypothesis'].apply(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad891e8-eb0a-43e8-b9f1-1033c9077d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_tensors = []\n",
    "for index, row in test_data.iterrows():\n",
    "    vector1 = row['premise_vec']\n",
    "    vector2 = row['hypothesis_vec']\n",
    "\n",
    "    stacked_tensor = torch.concatenate((vector1, vector2), dim=0)\n",
    "    \n",
    "    stacked_tensors.append(stacked_tensor)\n",
    "test_data['combined_vector'] = stacked_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82109d-b91d-4ee5-853d-a4523085879d",
   "metadata": {},
   "source": [
    "## DeBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997661e5-9ea7-4264-bf25-b187e6debf3d",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a5cb7f9-181e-4cec-96d5-e258b7e06f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "model = DebertaModel.from_pretrained('microsoft/deberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf0475-1ec8-4347-ba9e-aeb08380c268",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c540fdf0-c5fe-452e-b681-8dbd14bce661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "def tokenize(premises, hypotheses, max_length=128):\n",
    "    # Tokenize a list of premise and hypothesis pairs\n",
    "    tokenized_output = tokenizer(premises, hypotheses,\n",
    "                                 padding='max_length',\n",
    "                                 truncation=True,\n",
    "                                 max_length=max_length,\n",
    "                                 return_tensors=\"pt\",\n",
    "                                 truncation_strategy='only_second')\n",
    "    \n",
    "    return tokenized_output\n",
    "    \n",
    "tokenized_test = tokenize([str(p) for p in test_data[\"premise\"].tolist()], [str(h) for h in test_data[\"hypothesis\"].tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b53f0-dc12-4ce4-82e1-dcc71bec9294",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1792c16f-e651-4dd2-9317-a8702b63d7db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/53\n",
      "2/53\n",
      "3/53\n",
      "4/53\n",
      "5/53\n",
      "6/53\n",
      "7/53\n",
      "8/53\n",
      "9/53\n",
      "10/53\n",
      "11/53\n",
      "12/53\n",
      "13/53\n",
      "14/53\n",
      "15/53\n",
      "16/53\n",
      "17/53\n",
      "18/53\n",
      "19/53\n",
      "20/53\n",
      "21/53\n",
      "22/53\n",
      "23/53\n",
      "24/53\n",
      "25/53\n",
      "26/53\n",
      "27/53\n",
      "28/53\n",
      "29/53\n",
      "30/53\n",
      "31/53\n",
      "32/53\n",
      "33/53\n",
      "34/53\n",
      "35/53\n",
      "36/53\n",
      "37/53\n",
      "38/53\n",
      "39/53\n",
      "40/53\n",
      "41/53\n",
      "42/53\n",
      "43/53\n",
      "44/53\n",
      "45/53\n",
      "46/53\n",
      "47/53\n",
      "48/53\n",
      "49/53\n",
      "50/53\n",
      "51/53\n",
      "52/53\n",
      "53/53\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(model, tokenized_input):\n",
    "    # Move tokenized input to the same device as the model\n",
    "    input_ids = tokenized_input['input_ids'].to(model.device)\n",
    "    attention_mask = tokenized_input['attention_mask'].to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, get model outputs\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get the embeddings from the last hidden state\n",
    "        # You could opt for other strategies like taking the output of the [CLS] token\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return embeddings.cpu().numpy()  # Assuming you want to continue in numpy, move tensor to CPU and convert to numpy\n",
    "\n",
    "def get_embeddings_in_chunks(model, tokenized_inputs, chunk_size=128):\n",
    "    # Split tokenized input into smaller chunks\n",
    "    all_embeddings = []\n",
    "    input_chunks = []\n",
    "\n",
    "    for i in range(0, len(tokenized_inputs['input_ids']), chunk_size):\n",
    "        input_chunks.append(tokenized_inputs[i:i + chunk_size])\n",
    "    \n",
    "    index = 1\n",
    "    for chunk in input_chunks:\n",
    "        print(f'{index}/{len(input_chunks)}')\n",
    "        \n",
    "        embeddings = get_embeddings(model, chunk) \n",
    "        all_embeddings.append(embeddings)\n",
    "        \n",
    "        index+=1\n",
    "\n",
    "    # Concatenate all chunk embeddings\n",
    "    return np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "X_test = get_embeddings_in_chunks(model, tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512959dd-0440-4076-807b-9048723a4cf2",
   "metadata": {},
   "source": [
    "## sBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bbb60-17d8-4640-afe2-b555d53c46a4",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88491110-def1-46e1-b89d-3c4db380e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198ea13-2b06-4cfb-8537-6b0bf2d9b514",
   "metadata": {},
   "source": [
    "### Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "086d2fe2-3764-4e69-b15b-27c633a2ba7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cebcb67210473cb1f89c965e98814b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169005772845457da777b213cdb3fc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to apply model encoding with a progress bar\n",
    "def encode_with_progress(series):\n",
    "    return series.astype(str).progress_apply(model.encode)\n",
    "\n",
    "# Function to combine premise and hypothesis\n",
    "def combine_embeddings(embedding1, embedding2):\n",
    "    # Element-wise difference\n",
    "    difference = np.subtract(embedding1, embedding2)\n",
    "    \n",
    "    # Element-wise product\n",
    "    product = np.multiply(embedding1, embedding2)\n",
    "    \n",
    "    # Concatenate features\n",
    "    combined_embedding = np.concatenate((embedding1, embedding2, difference, product))\n",
    "    \n",
    "    return combined_embedding\n",
    "\n",
    "# Initialize tqdm within the pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Embedding the data\n",
    "test_data['embedding_premise'] = encode_with_progress(test_data['premise'])\n",
    "test_data['embedding_hypothesis'] = encode_with_progress(test_data['hypothesis'])\n",
    "\n",
    "# Combining the data\n",
    "test_data['combined_embedding'] = test_data.apply(lambda x: combine_embeddings(x['embedding_premise'], x['embedding_hypothesis']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b9c4e-d4f4-4516-ad75-8b4597a43337",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e694958e-93c3-4a21-9c7d-7e5a87a57437",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = test_data[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35531f-26e1-4e2e-955c-586471a2912f",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6411af81-04c9-41c8-86e1-59c3ed1ce1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_glove = svm_glove.predict(test_data[\"combined_vector\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0df5ba5d-f4fb-4a5c-8d6b-cb1e9362f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64      3259\n",
      "           1       0.66      0.76      0.71      3478\n",
      "\n",
      "    accuracy                           0.68      6737\n",
      "   macro avg       0.68      0.67      0.67      6737\n",
      "weighted avg       0.68      0.68      0.67      6737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69875721-e87f-4f3e-890a-422663ce5522",
   "metadata": {},
   "source": [
    "## DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb0d9df0-87c4-40fc-8a7f-99de0c554a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66      3259\n",
      "           1       0.68      0.66      0.67      3478\n",
      "\n",
      "    accuracy                           0.67      6737\n",
      "   macro avg       0.67      0.67      0.67      6737\n",
      "weighted avg       0.67      0.67      0.67      6737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_DeBERTa = svm_DeBERTa.predict(X_test)\n",
    "print(classification_report(y_val, y_pred_DeBERTa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b184da-1c9d-40c5-b7c7-ea8d9d00d701",
   "metadata": {},
   "source": [
    "## sBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "731ffa55-d654-4c6e-a773-2acd1c4542ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      3259\n",
      "           1       0.74      0.83      0.78      3478\n",
      "\n",
      "    accuracy                           0.76      6737\n",
      "   macro avg       0.77      0.76      0.76      6737\n",
      "weighted avg       0.77      0.76      0.76      6737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_sBERT = svm_sBERT.predict(test_data['combined_embedding'].tolist())\n",
    "print(classification_report(y_val, y_pred_sBERT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67a25331-6bfa-4149-a35a-4d441a80fcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72      3259\n",
      "           1       0.73      0.80      0.76      3478\n",
      "\n",
      "    accuracy                           0.74      6737\n",
      "   macro avg       0.74      0.74      0.74      6737\n",
      "weighted avg       0.74      0.74      0.74      6737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_combined = (y_pred_glove*68 + y_pred_DeBERTa*67 + y_pred_sBERT*77) / 212\n",
    "y_pred_final = np.where(y_pred_combined >= 0.5, 1, 0)\n",
    "print(classification_report(y_val, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0745d8c1-ef3a-4e8e-bcbf-14983bac1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"prediction\": y_pred_sBERT})\n",
    "df.to_csv('Group_9_A.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
