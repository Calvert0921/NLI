{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9862e40c-0595-441b-80c4-e9a4588f0ea2",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b73f17-f9ec-4525-ab69-5bfa51e8522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install torchtext==0.6.0\n",
    "# !pip install transformers sentence-transformers\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d41c1b-8db2-47b0-bb7e-7159c182eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string\n",
    "from torchtext.vocab import GloVe\n",
    "import torch\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import random\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444a9ac-7fb5-425f-a3cc-1f8e64b061b2",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c38da6-06a4-4e3f-8464-ae1232c171df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "val_data = pd.read_csv('dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e2dd4-0504-4028-8210-56556ef933f7",
   "metadata": {},
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597f37b6-0c75-46fe-81ef-918929f840c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "count = 0\n",
    "num_inv = 0\n",
    "num_oov = 0\n",
    "glove_mode = True\n",
    "\n",
    "update_inv_mode = False\n",
    "update_oov_mode = False\n",
    "word_mode = (glove_mode, update_inv_mode, update_oov_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7f05ee-b09f-4cd6-b4b2-e48dec0c880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy English tokenizer\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "inputs = data.Field(lower=True, tokenize=lambda text: [token.text for token in spacy_en.tokenizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c826b7b6-6fc9-498e-b26c-d359c9981126",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['processed_premise'] = train_data['premise'].astype(str).apply(inputs.preprocess)\n",
    "train_data['processed_hypothesis'] = train_data['hypothesis'].astype(str).apply(inputs.preprocess)\n",
    "\n",
    "val_data['processed_premise'] = val_data['premise'].astype(str).apply(inputs.preprocess)\n",
    "val_data['processed_hypothesis'] = val_data['hypothesis'].astype(str).apply(inputs.preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e3ec0-1fc0-4737-a845-2c1e1bb13bd2",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f29dbb5-1e9f-4c51-a799-c4e967b2267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "EMBEDDING_DIM = 300\n",
    "glove = GloVe(name='840B', dim=EMBEDDING_DIM) # Using GloVe with 840 billion tokens and 300 dimensions\n",
    "\n",
    "# GloVe's vocabulary and vectors\n",
    "wv_dict = glove.stoi  # Word to index mapping\n",
    "wv_arr = glove.vectors  # Embedding matrix\n",
    "wr_size = glove.dim  # Embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de437a5-3539-48ba-8caa-86cf88ffe859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(tokens):\n",
    "    embeddings = torch.zeros(300)\n",
    "    for word in tokens:\n",
    "        if word in wv_dict:\n",
    "            embeddings += wv_arr[wv_dict[word]]\n",
    "        else:\n",
    "            embeddings += torch.Tensor([random.uniform(-0.05, 0.05) for i in range(EMBEDDING_DIM)])\n",
    "    embeddings = embeddings / len(tokens)\n",
    "    return embeddings\n",
    "\n",
    "def combine_embeddings(embedding1, embedding2):\n",
    "    # Element-wise difference\n",
    "    difference = np.subtract(embedding1, embedding2)\n",
    "    \n",
    "    # Element-wise product\n",
    "    product = np.multiply(embedding1, embedding2)\n",
    "    \n",
    "    # Concatenate features\n",
    "    combined_embedding = np.concatenate((embedding1, embedding2, difference, product))\n",
    "    \n",
    "    return combined_embedding\n",
    "    \n",
    "train_data['premise_vec'] = train_data['processed_premise'].apply(embedding)\n",
    "train_data['hypothesis_vec'] = train_data['processed_hypothesis'].apply(embedding)\n",
    "\n",
    "val_data['premise_vec'] = val_data['processed_premise'].apply(embedding)\n",
    "val_data['hypothesis_vec'] = val_data['processed_hypothesis'].apply(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d64592-05f7-4e47-b5f7-28d0904f4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['combined_vector'] = train_data.apply(lambda x: combine_embeddings(x['premise_vec'], x['hypothesis_vec']), axis=1)\n",
    "val_data['combined_vector'] = val_data.apply(lambda x: combine_embeddings(x['premise_vec'], x['hypothesis_vec']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6386ba-aad5-4518-9d3c-723f0a436865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_tensors = []\n",
    "# for index, row in train_data.iterrows():\n",
    "#     vector1 = row['premise_vec']\n",
    "#     vector2 = row['hypothesis_vec']\n",
    "\n",
    "#     stacked_tensor = torch.concatenate((vector1, vector2), dim=0)\n",
    "    \n",
    "#     stacked_tensors.append(stacked_tensor)\n",
    "# train_data['combined_vector'] = stacked_tensors\n",
    "\n",
    "# stacked_tensors = []\n",
    "# for index, row in val_data.iterrows():\n",
    "#     vector1 = row['premise_vec']\n",
    "#     vector2 = row['hypothesis_vec']\n",
    "\n",
    "#     stacked_tensor = torch.concatenate((vector1, vector2), dim=0)\n",
    "    \n",
    "#     stacked_tensors.append(stacked_tensor)\n",
    "# val_data['combined_vector'] = stacked_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2713c65-c3d8-448b-8041-3ae72125034e",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5a3651-9d6e-484e-9cc3-a2e6eae524ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "X_train, y_train = np.array(train_data[\"combined_vector\"].tolist()), np.array(train_data[\"label\"].tolist())\n",
    "# X_bootstrap_samples = {}\n",
    "# y_bootstrap_samples = {}\n",
    "\n",
    "# for i in range(3):\n",
    "#     n_samples = len(X_train)\n",
    "    \n",
    "#     bootstrap_indices = np.random.randint(0, n_samples, size=n_samples)\n",
    "    \n",
    "#     X_bootstrap_samples[f'X_train_{i+1}'] = X_train[bootstrap_indices]\n",
    "#     y_bootstrap_samples[f'y_train_{i+1}'] = y_train[bootstrap_indices]\n",
    "\n",
    "X_val, y_val = val_data[\"combined_vector\"].tolist(), val_data[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8f369-d6ba-4ab3-90b2-afe7633d7751",
   "metadata": {},
   "source": [
    "## First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72c4fc-4e76-402b-9be9-159856dab6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_1 = SVC(kernel='rbf', C=1) \n",
    "# svm_1.fit(X_bootstrap_samples['X_train_1'], y_bootstrap_samples['y_train_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189fa6e-fbee-420b-adfd-c846327359a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate\n",
    "# y_pred_1 = svm_1.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743d5e4-48a1-4c51-9d6f-a60189b36016",
   "metadata": {},
   "source": [
    "## Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05613e06-8374-4fe1-9fe4-fa2cbd8ba144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_2 = SVC(kernel='rbf', C=1) \n",
    "# svm_2.fit(train_data[\"combined_vector\"].tolist(), train_data['label'].tolist())\n",
    "\n",
    "# # Evaluate\n",
    "# y_pred_2 = svm_2.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d4de4-5d7f-4787-b9bc-18242ff39487",
   "metadata": {},
   "source": [
    "## Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e83c3-f85a-41f0-aab9-48b1b5b9e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_3 = SVC(kernel='rbf', C=3.5) \n",
    "# svm_3.fit(train_data[\"combined_vector\"].tolist(), train_data['label'].tolist())\n",
    "\n",
    "# # Evaluate\n",
    "# y_pred_3 = svm_3.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3450a66-f1fb-43bd-b11b-b6a235d7d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64      3259\n",
      "           1       0.66      0.77      0.71      3478\n",
      "\n",
      "    accuracy                           0.68      6737\n",
      "   macro avg       0.68      0.67      0.67      6737\n",
      "weighted avg       0.68      0.68      0.67      6737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_4 = SVC(kernel='rbf', C=3) \n",
    "svm_4.fit(train_data[\"combined_vector\"].tolist(), train_data['label'].tolist())\n",
    "\n",
    "# Evaluate\n",
    "y_pred_4 = svm_4.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1fa68-9e91-4f5c-b186-38dcb1e809d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(svm_4, 'svm_glove.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabee47-1d4c-49ee-a8dd-aaa117610aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_combined = (y_pred_1*0.5 + y_pred_2 + y_pred_3 + y_pred_4*3) / 5.5\n",
    "# y_pred_final = np.where(y_pred_combined >= 0.5, 1, 0)\n",
    "# print(classification_report(y_val, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f562de-77cb-445c-88c8-b1975a68a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"prediction\": y_pred_1,\n",
    "#                   \"prediction2\": y_pred_2,\n",
    "#                   \"prediction3\": y_pred_3,\n",
    "#                   \"prediction4\": y_pred_4})\n",
    "# df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df9ff7-1286-4c3e-af0e-a1dcfd905ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"prediction\": y_pred_4})\n",
    "df.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
